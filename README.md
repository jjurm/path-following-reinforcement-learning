# Reinforcement learning for path following

Consider the task of a problem attempting to follow a path in a constrained environment with only a few lines to follow. We attempt this using end-to-end reinforcement learning and explore two algorithms for doing so: Deep Deterministic Policy Gradients (DDPG) and Proximal Policy Optimisation (PPO). We further explore different problem formulations to learn a path-following controller or the velocities of the agent directly, and report our findings.

## Report

The PDF containing the project's Report can be found <a href="https://github.com/jjurm/path-following-reinforcement-learning/blob/master/MRS_Project_7.pdf">here</a>.

<a href="https://github.com/jjurm/path-following-reinforcement-learning/blob/master/MRS_Project_7.pdf"><img src="https://raw.githubusercontent.com/jjurm/bonedoctor/master/assets/report-frontpage.png" width="232" height="300" /></a>

## Presentation slides

Slides used for the project's presentation can be found [here](https://slides.com/jurajmicko/mrs-project7-presentation/).

## Authors
* Juraj Micko (jm2186@cam.ac.uk)
* Kwot Sin Lee (ksl36@cam.ac.uk)
* Wilson Suen (wss28@cam.ac.uk)
